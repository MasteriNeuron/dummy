{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["![image](https://github.com/hrisikeshOfc/LangChain/assets/104005791/3fee4113-3207-4556-9711-7359bab29e6f)\n","\n","\n","## What is LangChain\n","\n","LangChain is a comprehensive framework designed to facilitate the development of applications using large language models (LLMs). Its primary goal is to simplify the integration of LLMs into your code by providing a range of tools and abstractions.\n","\n","One of the key features of LangChain is its standard interface for interacting with LLMs. This standardized interface allows developers to seamlessly switch between different LLMs and utilize multiple LLMs within the same application effortlessly.\n","\n","Moreover, LangChain offers a diverse collection of pre-trained LLMs. These models have undergone extensive training on vast datasets consisting of both text and code. Consequently, they are capable of performing various tasks such as text generation, summarization, question answering, and translation. These pre-trained LLMs are readily available for use in powering your applications.\n","\n","To aid developers in building LLM-driven applications, LangChain provides an assortment of tools. These tools include a debugger for troubleshooting, a visualization tool for enhancing understanding, and a command-line interface for streamlined development and testing processes.\n","\n","LangChain opens up a range of possibilities for application development with LLMs. Here are a few examples of applications that can be built using LangChain:\n","\n","1. Chatbots: LangChain enables the creation of chatbots that utilize LLMs for simulating conversations with human users. These chatbots can be employed across various domains such as customer service, education, and entertainment.\n","\n","2. Question answering systems: By leveraging LangChain, developers can build question answering systems powered by LLMs. These systems excel at responding to different types of questions, including factual queries, open-ended inquiries, and even creative prompts.\n","\n","3. Text generation systems: LangChain simplifies the development of text generation systems that harness the capabilities of LLMs. These systems can be utilized to generate diverse forms of text, including articles, blog posts, and even code.\n","\n","LangChain is an invaluable tool for developers interested in harnessing the potential of language models. Its user-friendly nature and comprehensive feature set make it an indispensable asset for creating efficient and effective LLM-driven applications.\n","\n","\n","## Different Components of LangChain\n","![lANGCHAIN COMPONENTS](https://github.com/hrisikesh-neogi/Database-Connect/assets/78023847/e8146638-33a0-4806-9b53-a9ef15a4a8f8)\n","\n","LangChain is a framework that streamlines the development of language model-powered applications. It encompasses several components that facilitate the creation of such applications:\n","\n","1. **Schema:**\n","  LangChain offers a schema language for describing the data used by an application. This enables developers to define the structure and format of the data.\n","\n","  The LangChain schema is a set of definitions that describe the different types of data that can be used with LangChain. The schema includes definitions for data types such as text, chat messages, documents, and examples. It also includes definitions for entities such as agents, chains, and memories.\n","\n","  The LangChain schema is used by the LangChain framework to interpret and process data. When you use LangChain to create a chatbot or other AI application, you will need to use data that conforms to the LangChain schema. This ensures that your application will be able to correctly interpret and process the data.\n","\n","  The LangChain schema is constantly evolving as the LangChain framework is developed. You can find the latest version of the schema in the LangChain documentation.\n","\n","  Here are some of the types of data that are defined in the LangChain schema:\n","\n","  * **Text:** Text is a sequence of characters. It can be used to represent words, sentences, paragraphs, and documents.\n","  * **Chat messages:** Chat messages are text messages that are exchanged between users and AI agents. They can be used to ask questions, provide information, and interact with AI agents in a natural way.\n","  * **Documents:** Documents are unstructured pieces of data. They can contain text, images, videos, and other types of data.\n","  * **Examples:** Examples are input/output pairs that represent inputs to a function and then expected output. They can be used in both training and evaluation of models.\n","\n","\n","2. **Models:**\n","  Pre-trained models provided by LangChain serve as representations of real-world entities. These models have undergone extensive training on large datasets and can be utilized to power applications.\n","\n","  LangChain supports two types of models:\n","\n","  * **Large language models (LLMs):** LLMs are trained on a massive dataset of text and code. They can be used to perform a variety of tasks, such as answering questions, generating text, and translating languages.\n","  * **Chat models:** Chat models are a type of LLM that is specifically trained to have conversations with humans. They can be used to create chatbots that can provide customer service, answer questions, and provide companionship.\n","\n","  LangChain provides a standard interface for interacting with models. This interface makes it easy to use different models in your applications. You can also combine different models to create more powerful applications.\n","\n","  Here are some of the models that are supported by LangChain:\n","\n","  * **Bard:** Bard is a large language model from Google AI. It is trained on a massive dataset of text and code. Bard can be used to perform a variety of tasks, such as answering questions, generating text, and translating languages.\n","  * **GPT-3:** GPT-3 is a large language model from OpenAI. It is trained on a massive dataset of text and code. GPT-3 can be used to perform a variety of tasks, such as answering questions, generating text, and translating languages.\n","  * **DialoGPT:** DialoGPT is a chat model from OpenAI. It is trained on a massive dataset of human-to-human conversations. DialoGPT can be used to create chatbots that can provide customer service, answer questions, and provide companionship.\n","  * **LaMDA:** LaMDA is a chat model from Google AI. It is trained on a massive dataset of human-to-human conversations. LaMDA can be used to create chatbots that can provide customer service, answer questions, and provide companionship.\n","\n","  You can find more information about the models that are supported by LangChain in the [LangChain documentation](https://python.langchain.com/docs/modules/model_io/models/).\n","\n","\n","3. **Prompts:**\n","  Prompts are text fragments used to interact with a model. LangChain provides a range of predefined prompts that can be employed for effective communication with the models.\n","\n","  In LangChain, a prompt is a piece of text that is used to guide a large language model (LLM) in its response. Prompts can be used to answer questions, generate text, or perform other tasks.\n","\n","  There are two main types of prompts in LangChain:\n","\n","  * **Static prompts:** Static prompts are a fixed piece of text that is used every time the LLM is asked a question. For example, a static prompt for answering questions about the weather might be \"What is the weather like today?\"\n","  * **Dynamic prompts:** Dynamic prompts are a piece of text that is generated based on the specific question that is being asked. For example, a dynamic prompt for answering questions about the weather might be \"What is the weather like in San Francisco today?\"\n","\n","  LangChain provides a number of classes and functions that can be used to create and work with prompts. These classes and functions make it easy to create prompts that are both effective and efficient.\n","\n","  Here are some of the benefits of using prompts in LangChain:\n","\n","  * **Prompts can be used to improve the accuracy of LLM responses.** By providing the LLM with a specific context, prompts can help the LLM to focus on the relevant information and to generate more accurate responses.\n","  * **Prompts can be used to improve the fluency of LLM responses.** By providing the LLM with a clear structure, prompts can help the LLM to generate more fluent and coherent responses.\n","  * **Prompts can be used to improve the creativity of LLM responses.** By providing the LLM with a specific goal, prompts can help the LLM to generate more creative and interesting responses.\n","\n","  If you are interested in using prompts in LangChain, you can find more information in the [LangChain documentation](https://docs.langchain.com/docs/components/prompts/#:~:text=A%20%22prompt%22%20refers%20to%20the,and%20working%20with%20prompts%20easy).\n","\n","4. **Indexes:**\n","  LangChain incorporates various indexes that facilitate rapid data retrieval. These indexes serve as data structures for efficient searching and retrieval operations.\n","\n","  Indexes refer to ways of structuring documents so that Language Models (LLMs) can effectively interact with them. This module provides utility functions for document processing, different types of indexes, and examples of how to use indexes in chains.\n","\n","  Indexes are commonly used in a \"retrieval\" step, which involves taking a user's query and returning the most relevant documents. It's important to note that indexes can serve purposes other than retrieval, and retrieval itself can employ logic other than just using indexes to find relevant documents. To accommodate this, LangChain introduces the concept of a \"Retriever\" interface, which is the primary interface used in most chains.\n","\n","  In most cases, when we talk about indexes and retrieval, we are referring to unstructured data, such as text documents. For structured data (like SQL tables) or working with APIs, LangChain provides specific functionality tailored to those use cases. Currently, the main index and retrieval types supported by LangChain are focused on vector databases, so a significant portion of the functionality discussed here is related to that.\n","\n","  * **Document Loaders** - Document Loaders are responsible for fetching and loading documents from various sources.\n","\n","  * **Text Splitters**- Text Splitters are responsible for dividing large text documents into smaller chunks or segments.\n","\n","  * **VectorStores**- VectorStores are the most common type of index used, relying on embeddings or vector representations of documents.\n","\n","  * **Retrievers**- Retrievers define an interface for retrieving relevant documents, which can then be combined with language models for further processing.\n","\n","\n","\n","5. **Memory:**\n","  Memory refers to the data storage structure used by an application. LangChain supports multiple memory types that enable developers to store and manage data effectively.\n","\n","  In LangChain, memory is a store of data that can be used by agents. It can be used to store information about the world, about users, and about previous interactions.\n","\n","  There are two main types of memory in LangChain:\n","\n","  * **Conversational memory:** Conversational memory stores information about the current conversation, such as the chat messages that have been exchanged and the responses that have been generated. Conversational memory can be used to improve the fluency and coherence(*Coherence refers to the logical and meaningful connection between ideas within a text or discourse, ensuring clarity and understanding for the reader or listener.* ) of responses, as well as to provide context for future interactions.\n","  * **Long-term memory:** Long-term memory stores information about the world, such as facts, concepts, and relationships. Long-term memory can be used to answer questions, generate text, and perform other tasks.\n","\n","  LangChain provides a number of classes and functions that can be used to create and work with memory. These classes and functions make it easy to create memory stores that are both effective and efficient.\n","\n","  Here are some of the benefits of using memory in LangChain:\n","\n","  * **Memory can be used to improve the fluency and coherence of responses.** By storing information about the current conversation, memory can help agents to generate more fluent and coherent responses.\n","  * **Memory can be used to provide context for future interactions.** By storing information about previous interactions, memory can help agents to provide more relevant and informative responses in the future.\n","  * **Memory can be used to answer questions.** By storing information about the world, memory can help agents to answer questions about a variety of topics.\n","  * **Memory can be used to generate text.** By storing information about the world, memory can help agents to generate text that is both factual and creative.\n","\n","  If you are interested in using memory in LangChain, you can find more information in the LangChain documentation.\n","\n","  Here are some additional resources that you may find helpful:\n","\n","  * LangChain memory documentation: https://docs.langchain.com/docs/components/memory/\n","  * GitHub repository for LangChain: https://github.com/hwchase17/langchain\n","\n","\n","\n","6. **Chains:**\n","  Chains represent sequences of steps used to execute specific tasks. LangChain offers a collection of pre-defined chains that developers can employ to streamline the task execution process.\n","\n","  In LangChain, a chain is a sequence of agents that are used to perform a task. Chains can be used to create complex AI applications that can perform a variety of tasks.\n","\n","  Here are some of the benefits of using chains in LangChain:\n","\n","  * **Chains can be used to improve the performance of AI applications.** By chaining together different agents, LangChain can take advantage of the strengths of each agent to perform a task more effectively.\n","  * **Chains can be used to improve the accuracy of AI applications.** By chaining together different agents, LangChain can compare the outputs of each agent and identify the most accurate output.\n","  * **Chains can be used to improve the scalability of AI applications.** By chaining together different agents, LangChain can handle large datasets and complex tasks.\n","\n","  Here are some of the different types of chains that can be created in LangChain:\n","\n","  * **Simple chains:** Simple chains are a sequence of agents that are executed in a single pass. Simple chains are often used for tasks that can be performed by a single agent, such as answering questions or generating text.\n","  * **Complex chains:** Complex chains are a sequence of agents that are executed in multiple passes. Complex chains are often used for tasks that require multiple agents to work together, such as translating languages or writing different kinds of creative content.\n","  * **End-to-end chains:** End-to-end chains are a sequence of agents that are used to perform a complete task, from start to finish. End-to-end chains are often used for tasks that require multiple agents to work together and that require a lot of data to be processed, such as creating a chatbot or writing a book.\n","\n","  If you are interested in using chains in LangChain, you can find more information in the LangChain documentation.\n","\n","  Here are some additional resources that you may find helpful:\n","\n","  * LangChain chains documentation: https://docs.langchain.com/docs/components/chains/\n","\n","  * GitHub repository for LangChain: https://github.com/hwchase17/langchain\n","\n","7. **Agents:**\n","  Agents are software programs responsible for performing tasks. LangChain provides a set of pre-defined agents that can be utilized to execute specific operations effectively.\n","\n","  In LangChain, an agent is a software program that can interact with the world and with humans. Agents can be used to perform a variety of tasks, such as answering questions, generating text, and translating languages.\n","\n","  There are two main types of agents in LangChain:\n","\n","  * **Action agents:** Action agents are agents that can perform a specific action, such as answering a question or generating text. Action agents are often used in simple chains.\n","  * **Plan-and-execute agents:** Plan-and-execute agents are agents that can plan and execute a sequence of actions. Plan-and-execute agents are often used in complex chains.\n","\n","  Here are some of the benefits of using agents in LangChain:\n","\n","  * **Agents can be used to improve the performance of AI applications.** By using agents, LangChain can take advantage of the strengths of each agent to perform a task more effectively.\n","  * **Agents can be used to improve the accuracy of AI applications.** By using agents, LangChain can compare the outputs of each agent and identify the most accurate output.\n","  * **Agents can be used to improve the scalability of AI applications.** By using agents, LangChain can handle large datasets and complex tasks.\n","\n","  Here are some of the different types of agents that can be used in LangChain:\n","\n","  * **Large language models (LLMs):** LLMs are trained on a massive dataset of text and code. They can be used to perform a variety of tasks, such as answering questions, generating text, and translating languages.\n","  * **Chat models:** Chat models are a type of LLM that is specifically trained to have conversations with humans. They can be used to create chatbots that can provide customer service, answer questions, and provide companionship.\n","  * **Utility agents:** Utility agents are agents that can perform a variety of tasks, such as searching the web, accessing databases, and executing code. Utility agents are often used in complex chains.\n","  * **Custom agents:** Custom agents are agents that are created by developers. Custom agents can be used to perform any task that can be programmed.\n","\n","  If you are interested in using agents in LangChain, you can find more information in the LangChain documentation.\n","\n","  Here are some additional resources that you may find helpful:\n","\n","  * LangChain agents documentation: https://docs.langchain.com/docs/components/agents/\n","  * Blog post on using agents with LangChain: https://tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/\n","  * GitHub repository for LangChain: https://github.com/hwchase17/langchain\n","\n","By utilizing these components, a wide array of applications powered by language models can be built using LangChain. Here are some examples of how these components can be applied:\n","\n"],"metadata":{"id":"2Wx0kAoaOx61"}},{"cell_type":"markdown","source":["## How to install LangChain\n","\n","1. Install LangChain by running the following command:\n","2. Install openai"],"metadata":{"id":"XbE6SV39Oymm"}},{"cell_type":"code","source":["!pip install langchain openai -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWqjvKKeQAmH","executionInfo":{"status":"ok","timestamp":1687934992616,"user_tz":-330,"elapsed":9392,"user":{"displayName":"Hrisikesh Neogi","userId":"10765762352392192914"}},"outputId":"f8335f59-3286-4865-9914-89fa1ec43d27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# import langchain\n","import langchain\n","from langchain.llms import OpenAI\n","import os"],"metadata":{"id":"jXmjsJTQQVbz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set your OpenAI API key\n","# os.environ['OPENAI_API_KEY'] = \"enter_your_key\"\n","os.environ['OPENAI_API_KEY'] = \"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\"\n","\n","\n","# Create an OpenAI language model\n","model = OpenAI(temperature = 0.9)"],"metadata":{"id":"PrXqkDr2QP1y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The `temperature` parameter is a crucial element in OpenAI's LangChain and the `OpenAI` class library. It plays a significant role in controlling the level of randomness in generated text. By adjusting the temperature, you can influence the output's predictability and coherence.\n","\n","When the temperature is set to a lower value, the resulting text becomes more predictable and coherent. Conversely, a higher temperature leads to more creative and unpredictable text. Essentially, the temperature parameter determines the likelihood of the model selecting words with lower probabilities.\n","\n","For tasks that require original and creative text, such as poetry or code generation, temperatures between 0.1 and 0.5 are often employed. On the other hand, for tasks necessitating factual and coherent text, like news articles or question answering, temperatures ranging from 0.7 to 1.0 are commonly used.\n","\n","The specific temperature value chosen can yield different outcomes depending on the application. For instance, when generating text for a chatbot, a lower temperature ensures coherency and ease of understanding. In contrast, a higher temperature allows the model to exhibit more creativity and originality, which might be desirable for creative writing projects.\n","\n","To summarize the effects of various temperature values:\n","\n","| Temperature | Effect |\n","|---|---|\n","| 0 | The model always selects the most likely word. |\n","| 0.1 | The model is slightly less inclined to select the most likely word. |\n","| 0.5 | The model is equally likely to select any word. |\n","| 1.0 | The model is equally likely to select any word, regardless of likelihood. |\n","\n","In the `OpenAI` class within the LangChain library, the `temperature` parameter governs the randomness of responses generated by the OpenAI GPT-3 language model. A temperature of 0 results in highly deterministic responses, where the output remains consistent for a given prompt. Conversely, a temperature of 1 introduces significant variation in the responses.\n","\n","Typically, higher temperatures yield more creative and interesting responses, albeit potentially less coherent. Conversely, lower temperatures produce more predictable and coherent responses, but they might lack creativity.\n","\n","The default value for the `temperature` parameter is 0.7, which serves as a suitable starting point for most tasks. However, if you wish to explore different values, you can experiment with a range between 0 and 1.\n","\n","For instance, consider the following code snippet that initializes an `OpenAI` model with a temperature of 0.9:\n","\n","```python\n","model = OpenAI(temperature=0.9)\n","```\n","\n","By utilizing this model, you can generate responses that are more creative and intriguing compared to a model with a temperature of 0.7. However, be aware that the responses might be less coherent.\n","\n","Feel free to experiment with different values for the `temperature` parameter to discover the setting that best suits your specific task."],"metadata":{"id":"x7WRAr11fQt1"}},{"cell_type":"code","source":["# Generate text\n","print(model(\"Write a poem about a neural network.\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"759qHr4nQf-z","executionInfo":{"status":"ok","timestamp":1687863432845,"user_tz":-330,"elapsed":11294,"user":{"displayName":"Hrisikesh Neogi","userId":"10765762352392192914"}},"outputId":"2a351156-bd3b-4918-9a08-57e2d22dd58a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","A neural network, born from tech in its prime\n","Ponders and hums as its created in time\n","A symphony of bits and bytes on a quest\n","To learn and process data's endless request\n","\n","It maps out structures and patterns unseen\n","Recognizes keypoints that were previously mean\n","Uncovers patterns hidden in the depths of the sea\n","Of data and knowledge, what will it see?\n","\n","It looks at the world from a grid of neurons\n","Processing data in its dynamic regions\n","A web of connections, so intricate and fine\n","Interconnected, its learning all the time\n","\n","In a blink of an eye, it can see what’s within\n","An unbeatable asset, deep learning to win\n","A neural network, crafted from the very best\n","A tool of tech that’s truly crest.\n"]}]},{"cell_type":"code","source":["import langchain\n","\n","def generate_text(prompt, temperature):\n","  llm = langchain.OpenAI(temperature=temperature)\n","  response = llm(prompt)\n","  return response\n","\n","def main():\n","  prompt = \"Create a list of 2 ways that AI is changing the world today.\"\n","  temperature_low = 0.1\n","  temperature_high = 1.0\n","\n","  response_low = generate_text(prompt, temperature_low)\n","  print(f\"Temperature: {temperature_low} Response: {response_low}\\n\")\n","\n","  response_high = generate_text(prompt, temperature_high)\n","  print(f\"Temperature: {temperature_high} Response: {response_high}\")\n","\n","if __name__ == \"__main__\":\n","  main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jrWTL6dyfVU8","executionInfo":{"status":"ok","timestamp":1687863627519,"user_tz":-330,"elapsed":10567,"user":{"displayName":"Hrisikesh Neogi","userId":"10765762352392192914"}},"outputId":"bf1394c7-71c3-46c6-c0a4-b4853425e136"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Temperature: 0.1 Response: \n","\n","1. Automation: AI is being used to automate mundane tasks, freeing up time for more creative and meaningful work.\n","\n","2. Healthcare: AI is being used to diagnose and treat diseases, as well as to develop personalized treatments for patients.\n","\n","Temperature: 1.0 Response: \n","\n","1. Automation of Everyday Tasks: AI is increasingly being used for automated tasks such as customer service, virtual assistants, and even facial recognition.\n","\n","2. Smarter Machines: Machines powered by AI algorithms can now detect and respond to user queries for improving productivity in the workplace. AI is also being used to process and analyze large amounts of data for smarter decision making.\n"]}]},{"cell_type":"markdown","source":["As you can see, the two outputs are very different. The output generated with a temperature of 0.1 is more traditional and straightforward, while the output generated with a temperature of 1.0 is more creative and original. The temperature parameter can be used to control the creativity and randomness of the generated text, and it can be used to achieve different results depending on the specific application.\n","\n","\n","\n","Experimenting with different temperature values can help you to find the right balance of creativity and coherence for your specific application."],"metadata":{"id":"Ck-xC9ppg_47"}}]}